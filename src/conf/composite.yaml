defaults:
  - _self_

selector_model:
  threshold: 0.5
  encoder_name: "sentence-transformers/all-MiniLM-L6-v2"
  loss:
    l_comp: 0.1
    l_s: 0.01
    l_tv: 10.0
    tau: 0.07
  optim:
    lr: 5e-5
    weight_decay: 1e-2
    betas: [0.9, 0.999]

expert_model:
  encoder_name: "sentence-transformers/all-MiniLM-L6-v2"
  contrastive_tau: 0.07
  expert:
    num_experts: 4
    routing: "softmax"
    routing_tau: 1.0
    normalize: True
    dropout: 0.0
    factor_dim: 384
    factor_hidden: 0
    gate_hidden: 0
    gate_dropout: 0.0
    shared_transform: True
    transform_dropout: 0.0
    reconstruction_hidden: 0
    decoder_hidden: 384
  loss_weights:
    sent: 1.0
    token: 1.0        # set to null to disable token decoder + loss
    entropy: null     # removed entropy regularizer
    overlap: 1.0     # set to null to disable
    continuity: 1.0  # set to null to disable
    diversity: null   # removed diversity regularizer
    balance: 1.0   # set to null to disable
    attention: 1.0    # set to null to disable
  optim:
    lr: 5e-5
    weight_decay: 1e-2
    betas: [0.9, 0.999]
  prototype:
    lambda_cons: 1.0    # set to a float to enable consistency loss; null disables
    lambda_sep: 1.0     # set to a float to enable separation loss; null disables
    ema_decay: 0.5       # EMA decay for prototype updates
    margin: 0.3          # separation margin on cosine sims
    eps: 1e-6

train:
  eval_only: False
  validate_epoch: False
  stages_epochs: [5,5,5,5,5]
  group_random_pct: 0.30  # fraction of leaves to include per random union (0.1 = 10% of leaves; >1 treated as percent)
  group_random_trials: 10  # how many random unions to sample/report
  group_union_enabled: true  # if false, skip union-of-branches evaluation
  loss_weights:
    selector: 1.0
    expert: 1.0
  grad_clip: 1.0

diagnostics:
  interval_steps: null  # set to an integer to enable diagnostics; null disables
  max_leaves: 2         # number of leaves to sample per diagnostic run
  tensorboard_dir: ""   # if empty, uses Hydra run dir / 'tb'
  skip_eval: false      # when true, diagnostics run and evaluation metrics are skipped

data:
  rebuild_ds: False
  train:
    dataset: "wikiann"
    config: "en"
    batch_size: 32
    num_workers: 0
    subset: 1.0
    shuffle: True
  eval:
    dataset: "wikiann"
    config: "en"
    split: "validation"
    batch_size: 32
    num_workers: 0
    subset: 1.0
    shuffle: False
  dev:
    dataset: "wikiann"
    config: "en"
    split: "test"
    batch_size: 32
    num_workers: 0
    subset: 1.0
    shuffle: False  

runtime:
  num_threads: 8
  device: "cuda"

array: 0

dora:
  exclude: ["eval.*", "data.rebuild_ds", "logging.*"]

slurm:
  partition: "boost_usr_prod"
  gpus: 1
  mem_per_gpu: 32
  time: 240
  cpus_per_gpu: 8
  setup:
    - "module load python/3.11.7"
    - "source /leonardo/home/userexternal/slusetti/MoE/.venv/bin/activate"
    - "export SLURM_CPU_BIND=none"
    - "export HF_HOME=/leonardo_work/IscrC_LUSE/slusetti/hf-cache"
    - "export HF_DATASETS_CACHE=$HF_HOME/datasets"
    - "export TRANSFORMERS_CACHE=$HF_HOME/transformers"
    - "export HF_MODULES_CACHE=$HF_HOME/modules"
    - "export HF_HUB_CACHE=$HF_HOME/hub"
    - "export HUGGINGFACE_HUB_CACHE=$HF_HOME/hub"
    - "export HF_HUB_OFFLINE=1"
    - "export TRANSFORMERS_OFFLINE=1"
    - "export HF_DATASETS_OFFLINE=1"
